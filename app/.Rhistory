# splitting train and test into the x values and the variable labels
X_train_pca <- train_pca[, 1:49]
y_train_pca <- train_pca[, 50]
X_test_pca <- test_pca[, 1:49]
y_test_pca <- test_pca[, 50]
lda_fit_pca <- lda(X_train_pca, y_train_pca)
lda_pred_train_pca <- predict(lda_fit_pca, X_train_pca)
lda_pred_test_pca <- predict(lda_fit_pca, X_test_pca)
confusion_train_pca <- table(lda_pred_train_pca$class, y_train_pca)
confusion_test_pca <- table(lda_pred_test_pca$class, y_test_pca)
confusion_train_pca
confusion_test_pca
lda_pred_test_256
mean(lda_pred_test_256$class != y_test)
lda_fit256 <- lda(X_train, y_train)
lda_pred_train_256 <- predict(lda_fit256, X_train)
lda_pred_test_256 <- predict(lda_fit256, X_test)
confusion_train_256 <- table(lda_pred_train_256$class, y_train)
confusion_test_256 <- table(lda_pred_test_256$class, y_test)
mean(lda_pred_train_256$class != y_train)
mean(lda_pred_test_256$class != y_test)
lda_fit_pca <- lda(X_train_pca, y_train_pca)
lda_pred_train_pca <- predict(lda_fit_pca, X_train_pca)
lda_pred_test_pca <- predict(lda_fit_pca, X_test_pca)
confusion_train_pca <- table(lda_pred_train_pca$class, y_train_pca)
confusion_test_pca <- table(lda_pred_test_pca$class, y_test_pca)
mean(lda_pred_train_pca$class != y_train_pca)
mean(lda_pred_test_pca$class != y_test_pca)
h1<-data(diag(8),cbind(c(0.5,0.5)))
h2<-data(h1,h1)
h2
kronecker
kronecker
h2<-kronecker(h1,h1)
h1
?kronecker
diag(8)
h1<-kronecker(diag(8),cbind(c(0.5,0.5, 0.5)))
h1
h1<-kronecker(diag(8),cbind(c(2, 2)))
h1
h1<-kronecker(diag(nrow(data)),cbind(c(0.5, 0.5)))
h1
h2<-kronecker(h1,h1)
nrow(h1)
ncol(h1)
h1<-kronecker(diag(nrow(data)),cbind(c(0.5, 0.5)))
nrow(h1)
h1<-kronecker(diag(nrow(8)),cbind(c(0.5, 0.5)))
nrow(h1)
h1<-kronecker(diag(8),cbind(c(0.5, 0.5)))
nrow(h1)
h1
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h1
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
## I(x%*%h2) averages adjacent 2 by 2 pixel blocks
h1
h2<-kronecker(h1,h1)
## I(x%*%h2) averages adjacent 2 by 2 pixel blocks
h2
lda(y_train ~ I(X_train%*%h2))
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
lda(y_train ~ I(X_train%*%h2))
## I(x%*%h2) averages adjacent 2 by 2 pixel blocks
h1<-kronecker(diag(7),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
lda(y_train ~ I(X_train%*%h2))
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
lda(y_train ~ I(X_train%*%h2))
## I(x%*%h2) averages adjacent 2 by 2 pixel blocks
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
lda_fit_filter <- lda(y_train ~ I(X_train%*%h2))
lda_pred_train_filter <- predict(lda_fit_filter, X_train)
lda_fit_filter
lda_fit256
lda_fit_filter
lda_pred_train_filter <- predict(lda_fit_filter, I(X_train%*%h2))
X_train
lda_pred_test_filter <- predict(lda_fit_filter, X_test)
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
lda_fit_filter <- lda(y_train ~ I(X_train%*%h2))
lda_pred_train_filter <- predict(lda_fit_filter, X_train)
lda_pred_train_filter <- predict(lda_fit_filter, I(X_train%*%h2))
lda_pred_test_filter <- predict(lda_fit_filter, X_test)
X_train)
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
X_train_filter <- I(X_train%*%h2)
X_test_filter <- I(X_test%*%h2)
lda_fit_filter <- lda(X_train_filter, y_train)
lda_pred_train_filter <- predict(lda_fit_filter, X_train_filter)
lda_pred_test_filter <- predict(lda_fit_filter, X_test_filter)
confusion_train_filter <- table(lda_pred_train_filter$class, y_train)
confusion_test_filter <- table(lda_pred_test_filter$class, y_test)
mean(lda_pred_train_filter$class != y_train)
mean(lda_pred_test_filter$class != y_test)
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
X_train_filter <- I(X_train%*%h2)
X_test_filter <- I(X_test%*%h2)
lda_fit_filter <- lda(X_train_filter, y_train)
lda_pred_train_filter <- predict(lda_fit_filter, X_train_filter)
lda_pred_test_filter <- predict(lda_fit_filter, X_test_filter)
confusion_train_filter <- table(lda_pred_train_filter$class, y_train)
confusion_test_filter <- table(lda_pred_test_filter$class, y_test)
mean(lda_pred_train_filter$class != y_train)
mean(lda_pred_test_filter$class != y_test)
library(glmnet)
?Multinomial
multinom()
shiny::runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
# for heatmap
load(file="../output/clean_fire2")
# for heatmap
load(file="../output/clean_fire2.RData")
data = clean_fire2 %>%
select(YEAR, MONTH, INCIDENT_CLASSIFICATION_GROUP, LATITUDE, LONGITUDE) %>%
mutate(Severity = map_dbl(INCIDENT_CLASSIFICATION_GROUP, ~ switch(.x,
"Structural Fires" = 6,
"NonStructural Fires" = 5,
"Medical Emergencies" = 4,
"NonMedical Emergencies" = 3,
"NonMedical MFAs" = 2,
"Medical MFAs" = 1)))
library(chron)
library(ggmap)
library(magrittr)
devtools::install_github("dkahle/ggmap")
# for heatmap
load(file="../output/clean_fire2.RData")
data = clean_fire2 %>%
select(YEAR, MONTH, INCIDENT_CLASSIFICATION_GROUP, LATITUDE, LONGITUDE) %>%
mutate(Severity = map_dbl(INCIDENT_CLASSIFICATION_GROUP, ~ switch(.x,
"Structural Fires" = 6,
"NonStructural Fires" = 5,
"Medical Emergencies" = 4,
"NonMedical Emergencies" = 3,
"NonMedical MFAs" = 2,
"Medical MFAs" = 1)))
library(chron)
library(ggmap)
library(magrittr)
library(purrr)
library(dplyr)
devtools::install_github("dkahle/ggmap")
# for heatmap
load(file="../output/clean_fire2.RData")
data = clean_fire2 %>%
select(YEAR, MONTH, INCIDENT_CLASSIFICATION_GROUP, LATITUDE, LONGITUDE) %>%
mutate(Severity = map_dbl(INCIDENT_CLASSIFICATION_GROUP, ~ switch(.x,
"Structural Fires" = 6,
"NonStructural Fires" = 5,
"Medical Emergencies" = 4,
"NonMedical Emergencies" = 3,
"NonMedical MFAs" = 2,
"Medical MFAs" = 1)))
color = data.frame(
INCIDENT_CLASSIFICATION_GROUP = c("Structural Fires", "NonStructural Fires", "Medical Emergencies", "NonMedical Emergencies", "NonMedical MFAs", "Medical MFAs"),
color = c("#9d2933", "#ff4e20", "#faff72", "#ffc773", "#e9e7ef", "#ffffff"))
incidence <- merge(data, color, by = c("INCIDENT_CLASSIFICATION_GROUP","INCIDENT_CLASSIFICATION_GROUP"), all.y = F)
save(incidence, file="../output/incidence.RData")
shiny::runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp()
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
shiny::runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
shiny::runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
shiny::runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
library(pryr)
install.packages("pryr")
object_size(purrr)
library(purrr)
library(pryr)
object_size(purrr)
mem_used()
mem_used()
mem_used()
shiny::runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
knitr::opts_chunk$set(echo = TRUE)
# reading in data and making a y column depending on the corresponding data
set.seed(123)
zip_3 <- read.table("train_3.txt", header=FALSE, sep=",")
zip_3 <-as.matrix(cbind(zip_3, rep(3, nrow(zip_3))))
colnames(zip_3)[257] <- 'y'
zip_5 <-read.table("train_5.txt", header=FALSE, sep=",")
zip_5 <-as.matrix(cbind(zip_5, rep(5, nrow(zip_5))))
colnames(zip_5)[257] <- 'y'
zip_8 <-read.table("train_8.txt", header=FALSE, sep=",")
zip_8 <-as.matrix(cbind(zip_8, rep(8, nrow(zip_8))))
colnames(zip_8)[257] <- 'y'
# reading in data and making a y column depending on the corresponding data
set.seed(123)
zip_3 <- read.table("train_3.txt", header=FALSE, sep=",")
zip_3 <-as.matrix(cbind(zip_3, rep(3, nrow(zip_3))))
colnames(zip_3)[257] <- 'y'
zip_5 <-read.table("train_5.txt", header=FALSE, sep=",")
zip_5 <-as.matrix(cbind(zip_5, rep(5, nrow(zip_5))))
colnames(zip_5)[257] <- 'y'
zip_8 <-read.table("train_8.txt", header=FALSE, sep=",")
zip_8 <-as.matrix(cbind(zip_8, rep(8, nrow(zip_8))))
colnames(zip_8)[257] <- 'y'
# combining data into one matrix
data <- rbind(zip_3, zip_5, zip_8)
# sampling the data to make the train and test sets
sample <- sample.int(nrow(data), size = floor(0.7 * nrow(data)), replace = F)
train <- data[sample, ]
test <- data[-sample, ]
# splitting train and test into the x values and the variable labels
X_train <- train[, 1:256]
y_train <- train[, 257]
X_test <- test[, 1:256]
y_test <- test[, 257]
library(MASS)
lda_fit256 <- lda(X_train, y_train)
lda_pred_train_256 <- predict(lda_fit256, X_train)
lda_pred_test_256 <- predict(lda_fit256, X_test)
confusion_train_256 <- table(lda_pred_train_256$class, y_train)
confusion_test_256 <- table(lda_pred_test_256$class, y_test)
mean(lda_pred_train_256$class != y_train)
mean(lda_pred_test_256$class != y_test)
# performing pca and combining the adjusted data with the label
pca <- prcomp(data[, 1:256], scale. = TRUE)
pca_and_y <- cbind(pca$x[, 1:49], data[, 257])
colnames(pca_and_y)[50] <- "y"
# sampling the data to make the train and test sets
sample_pca <- sample.int(nrow(pca_and_y), size = floor(0.7 * nrow(pca_and_y)), replace = F)
train_pca <- pca_and_y[sample_pca, ]
test_pca <- pca_and_y[-sample_pca, ]
# sampling the data to make the train and test sets
sample_pca <- sample.int(nrow(pca_and_y), size = floor(0.7 * nrow(pca_and_y)), replace = F)
train_pca <- pca_and_y[sample_pca, ]
test_pca <- pca_and_y[-sample_pca, ]
# splitting train and test into the x values and the variable labels
X_train_pca <- train_pca[, 1:49]
y_train_pca <- train_pca[, 50]
X_test_pca <- test_pca[, 1:49]
y_test_pca <- test_pca[, 50]
lda_fit_pca <- lda(X_train_pca, y_train_pca)
lda_pred_train_pca <- predict(lda_fit_pca, X_train_pca)
lda_pred_test_pca <- predict(lda_fit_pca, X_test_pca)
confusion_train_pca <- table(lda_pred_train_pca$class, y_train_pca)
confusion_test_pca <- table(lda_pred_test_pca$class, y_test_pca)
mean(lda_pred_train_pca$class != y_train_pca)
mean(lda_pred_test_pca$class != y_test_pca)
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
X_train_filter <- I(X_train%*%h2)
X_test_filter <- I(X_test%*%h2)
lda_fit_filter <- lda(X_train_filter, y_train)
lda_pred_train_filter <- predict(lda_fit_filter, X_train_filter)
lda_pred_test_filter <- predict(lda_fit_filter, X_test_filter)
confusion_train_filter <- table(lda_pred_train_filter$class, y_train)
confusion_test_filter <- table(lda_pred_test_filter$class, y_test)
mean(lda_pred_train_filter$class != y_train)
mean(lda_pred_test_filter$class != y_test)
library(glmnet)
X_train_filte
X_train_filter
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
X_train_filter <- I(X_train%*%h2)
X_test_filter <- I(X_test%*%h2)
lda_fit_filter <- lda(X_train_filter, y_train)
lda_pred_train_filter <- predict(lda_fit_filter, X_train_filter)
lda_pred_test_filter <- predict(lda_fit_filter, X_test_filter)
confusion_train_filter <- table(lda_pred_train_filter$class, y_train)
confusion_test_filter <- table(lda_pred_test_filter$class, y_test)
mean(lda_pred_train_filter$class != y_train)
mean(lda_pred_test_filter$class != y_test)
mlr_cv <- cv.glmnet(x = X_train_filter,
y = y_train,
nfolds = 5,
type.measure = 'class',
alpha = 1,
family = 'multinomial')
mlr_train_error <- round(mean(predict(mlr_cv, X_train_filter, s = mlr_cv$lambda.min, type = "class") != y_train), 4)
mlr_test_error <- round(mean(predict(mlr_cv, X_test_filter, s = mlr_cv$lambda.min, type = "class") != y_test), 4)
results[4, ] <- c('Multinomal LR Filtered', mlr_train_error, mlr_test_error)
mlr_train_error
mlr_test_error
mlr_train_error
mlr_cv <- cv.glmnet(x = X_train_filter,
y = y_train,
nfolds = 5,
type.measure = 'class',
alpha = 1,
family = 'multinomial')
mlr_train_error <- mean(predict(mlr_cv, X_train_filter, s = mlr_cv$lambda.min, type = "class") != y_train)
mlr_test_error <- mean(predict(mlr_cv, X_test_filter, s = mlr_cv$lambda.min, type = "class") != y_test)
mlr_train_error
mlr_test_error
mlr_cv <- cv.glmnet(x = X_train_filter,
y = y_train,
nfolds = 5,
type.measure = 'class',
alpha = 1,
family = 'multinomial')
mlr_train_error <- mean(predict(mlr_cv, X_train_filter, s = mlr_cv$lambda.min, type = "class") != y_train)
mlr_test_error <- mean(predict(mlr_cv, X_test_filter, s = mlr_cv$lambda.min, type = "class") != y_test)
mlr_train_error
mlr_test_error
mlr_cv <- cv.glmnet(x = X_train_filter,
y = y_train,
nfolds = 5,
type.measure = 'class',
alpha = 1,
family = 'multinomial')
mean(predict(mlr_cv, X_train_filter, s = mlr_cv$lambda.min, type = "class") != y_train)
mean(predict(mlr_cv, X_test_filter, s = mlr_cv$lambda.min, type = "class") != y_test)
X_train$class
data.frame(X_train)$class
# reading in data and making a y column depending on the corresponding data
set.seed(4400)
zip_3 <- read.table("train_3.txt", header=FALSE, sep=",")
zip_3 <-as.matrix(cbind(zip_3, rep(3, nrow(zip_3))))
colnames(zip_3)[257] <- 'y'
zip_5 <-read.table("train_5.txt", header=FALSE, sep=",")
zip_5 <-as.matrix(cbind(zip_5, rep(5, nrow(zip_5))))
colnames(zip_5)[257] <- 'y'
zip_8 <-read.table("train_8.txt", header=FALSE, sep=",")
zip_8 <-as.matrix(cbind(zip_8, rep(8, nrow(zip_8))))
colnames(zip_8)[257] <- 'y'
# combining data into one matrix
data <- rbind(zip_3, zip_5, zip_8)
# sampling the data to make the train and test sets
sample <- sample.int(nrow(data), size = floor(0.8 * nrow(data)), replace = F)
train <- data[sample, ]
test <- data[-sample, ]
# splitting train and test into the x values and the variable labels
X_train <- train[, 1:256]
y_train <- train[, 257]
X_test <- test[, 1:256]
y_test <- test[, 257]
lda_fit256 <- lda(X_train, y_train)
lda_pred_train_256 <- predict(lda_fit256, X_train)
lda_pred_test_256 <- predict(lda_fit256, X_test)
confusion_train_256 <- table(lda_pred_train_256$class, y_train)
confusion_test_256 <- table(lda_pred_test_256$class, y_test)
mean(lda_pred_train_256$class != y_train)
mean(lda_pred_test_256$class != y_test)
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(glmnet)
# reading in data and making a y column depending on the corresponding data
set.seed(4400)
zip_3 <- read.table("train_3.txt", header=FALSE, sep=",")
zip_3 <-as.matrix(cbind(zip_3, rep(3, nrow(zip_3))))
colnames(zip_3)[257] <- 'y'
zip_5 <-read.table("train_5.txt", header=FALSE, sep=",")
zip_5 <-as.matrix(cbind(zip_5, rep(5, nrow(zip_5))))
colnames(zip_5)[257] <- 'y'
zip_8 <-read.table("train_8.txt", header=FALSE, sep=",")
zip_8 <-as.matrix(cbind(zip_8, rep(8, nrow(zip_8))))
colnames(zip_8)[257] <- 'y'
# combining data into one matrix
data <- rbind(zip_3, zip_5, zip_8)
# sampling the data to make the train and test sets
sample <- sample.int(nrow(data), size = floor(0.8 * nrow(data)), replace = F)
train <- data[sample, ]
test <- data[-sample, ]
# splitting train and test into the x values and the variable labels
X_train <- train[, 1:256]
y_train <- train[, 257]
X_test <- test[, 1:256]
y_test <- test[, 257]
lda_fit256 <- lda(X_train, y_train)
lda_pred_train_256 <- predict(lda_fit256, X_train)
lda_pred_test_256 <- predict(lda_fit256, X_test)
confusion_train_256 <- table(lda_pred_train_256$class, y_train)
confusion_test_256 <- table(lda_pred_test_256$class, y_test)
errors <- data.frame(Model = NA, training_error = NA, testing_error = NA)[FALSE,]
errors[1,] <- c("Full LDA", mean(lda_pred_train_256$class != y_train), mean(lda_pred_test_256$class != y_test))
# performing pca and combining the adjusted data with the label
pca <- prcomp(data[, 1:256], scale. = TRUE)
pca_and_y <- cbind(pca$x[, 1:49], data[, 257])
colnames(pca_and_y)[50] <- "y"
# sampling the data to make the train and test sets
sample_pca <- sample.int(nrow(pca_and_y), size = floor(0.8 * nrow(pca_and_y)), replace = F)
train_pca <- pca_and_y[sample_pca, ]
test_pca <- pca_and_y[-sample_pca, ]
# splitting train and test into the x values and the variable labels
X_train_pca <- train_pca[, 1:49]
y_train_pca <- train_pca[, 50]
X_test_pca <- test_pca[, 1:49]
y_test_pca <- test_pca[, 50]
lda_fit_pca <- lda(X_train_pca, y_train_pca)
lda_pred_train_pca <- predict(lda_fit_pca, X_train_pca)
lda_pred_test_pca <- predict(lda_fit_pca, X_test_pca)
confusion_train_pca <- table(lda_pred_train_pca$class, y_train_pca)
confusion_test_pca <- table(lda_pred_test_pca$class, y_test_pca)
errors[2,] <- c("49 Principal Components LDA", mean(lda_pred_train_pca$class != y_train_pca), mean(lda_pred_test_pca$class != y_test_pca))
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
X_train_filter <- I(X_train%*%h2)
X_test_filter <- I(X_test%*%h2)
lda_fit_filter <- lda(X_train_filter, y_train)
lda_pred_train_filter <- predict(lda_fit_filter, X_train_filter)
lda_pred_test_filter <- predict(lda_fit_filter, X_test_filter)
confusion_train_filter <- table(lda_pred_train_filter$class, y_train)
confusion_test_filter <- table(lda_pred_test_filter$class, y_test)
errors[3,] <- c("49 Principal Components LDA", mean(lda_pred_train_filter$class != y_train), mean(lda_pred_test_filter$class != y_test))
mlr_cv <- cv.glmnet(x = X_train_filter,
y = y_train,
nfolds = 5,
type.measure = 'class',
alpha = 1,
family = 'multinomial')
errors[4,] <- c("49 Principal Components LDA", mean(predict(mlr_cv, X_train_filter, s = mlr_cv$lambda.min, type = "class") != y_train), mean(predict(mlr_cv, X_test_filter, s = mlr_cv$lambda.min, type = "class") != y_test))
errors
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(glmnet)
# reading in data and making a y column depending on the corresponding data
set.seed(4400)
zip_3 <- read.table("train_3.txt", header=FALSE, sep=",")
zip_3 <-as.matrix(cbind(zip_3, rep(3, nrow(zip_3))))
colnames(zip_3)[257] <- 'y'
zip_5 <-read.table("train_5.txt", header=FALSE, sep=",")
zip_5 <-as.matrix(cbind(zip_5, rep(5, nrow(zip_5))))
colnames(zip_5)[257] <- 'y'
zip_8 <-read.table("train_8.txt", header=FALSE, sep=",")
zip_8 <-as.matrix(cbind(zip_8, rep(8, nrow(zip_8))))
colnames(zip_8)[257] <- 'y'
# combining data into one matrix
data <- rbind(zip_3, zip_5, zip_8)
# sampling the data to make the train and test sets
sample <- sample.int(nrow(data), size = floor(0.8 * nrow(data)), replace = F)
train <- data[sample, ]
test <- data[-sample, ]
# splitting train and test into the x values and the variable labels
X_train <- train[, 1:256]
y_train <- train[, 257]
X_test <- test[, 1:256]
y_test <- test[, 257]
lda_fit256 <- lda(X_train, y_train)
lda_pred_train_256 <- predict(lda_fit256, X_train)
lda_pred_test_256 <- predict(lda_fit256, X_test)
confusion_train_256 <- table(lda_pred_train_256$class, y_train)
confusion_test_256 <- table(lda_pred_test_256$class, y_test)
errors <- data.frame(Model = NA, training_error = NA, testing_error = NA)[FALSE,]
errors[1,] <- c("Full LDA", mean(lda_pred_train_256$class != y_train), mean(lda_pred_test_256$class != y_test))
# performing pca and combining the adjusted data with the label
pca <- prcomp(data[, 1:256], scale. = TRUE)
pca_and_y <- cbind(pca$x[, 1:49], data[, 257])
colnames(pca_and_y)[50] <- "y"
# sampling the data to make the train and test sets
sample_pca <- sample.int(nrow(pca_and_y), size = floor(0.8 * nrow(pca_and_y)), replace = F)
train_pca <- pca_and_y[sample_pca, ]
test_pca <- pca_and_y[-sample_pca, ]
# splitting train and test into the x values and the variable labels
X_train_pca <- train_pca[, 1:49]
y_train_pca <- train_pca[, 50]
X_test_pca <- test_pca[, 1:49]
y_test_pca <- test_pca[, 50]
lda_fit_pca <- lda(X_train_pca, y_train_pca)
lda_pred_train_pca <- predict(lda_fit_pca, X_train_pca)
lda_pred_test_pca <- predict(lda_fit_pca, X_test_pca)
confusion_train_pca <- table(lda_pred_train_pca$class, y_train_pca)
confusion_test_pca <- table(lda_pred_test_pca$class, y_test_pca)
errors[2,] <- c("49 Principal Components LDA", mean(lda_pred_train_pca$class != y_train_pca), mean(lda_pred_test_pca$class != y_test_pca))
h1<-kronecker(diag(8),cbind(c(0.5,0.5)))
h2<-kronecker(h1,h1)
X_train_filter <- I(X_train%*%h2)
X_test_filter <- I(X_test%*%h2)
lda_fit_filter <- lda(X_train_filter, y_train)
lda_pred_train_filter <- predict(lda_fit_filter, X_train_filter)
lda_pred_test_filter <- predict(lda_fit_filter, X_test_filter)
confusion_train_filter <- table(lda_pred_train_filter$class, y_train)
confusion_test_filter <- table(lda_pred_test_filter$class, y_test)
errors[3,] <- c("Filtered LDA", mean(lda_pred_train_filter$class != y_train), mean(lda_pred_test_filter$class != y_test))
mlr_cv <- cv.glmnet(x = X_train_filter,
y = y_train,
nfolds = 5,
type.measure = 'class',
alpha = 1,
family = 'multinomial')
errors[4,] <- c("Logistic Regression", mean(predict(mlr_cv, X_train_filter, s = mlr_cv$lambda.min, type = "class") != y_train), mean(predict(mlr_cv, X_test_filter, s = mlr_cv$lambda.min, type = "class") != y_test))
errors
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
shiny::runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
shiny::runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
shiny::runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp()
runApp()
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp()
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
shiny::runApp('College/Senior/2nd Semester/Applied Data Science/Project 2/app')
